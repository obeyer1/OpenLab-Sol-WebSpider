# OpenLab-CrawL
本仓库包含了第4题T1的代码实现
## 安装依赖

1.访问 [Python 官方网站](https://www.python.org/downloads/?spm=5176.28103460.0.0.40f75d27h7nWlt)下载最新版本的 Python 3.9 或更高版本。

2.将此仓库克隆或下载到本地计算机。

3.在命令行中运行以下命令来安装这些依赖库：
```bash
pip install -r requirements.txt
```
4.或者直接在命令行输入：
```bash
pip install requests beautifulsoup4 openpyxl jieba wordcloud 
```
## 使用方法
1.在Python环境中打开脚本

2.如需抓取不同页面，请在脚本中修改**url**，然后指定要查找的 <div> 标签的 class 属性值，在脚本中修改**_class**的内容，使其对应要抓取的页面。


## 运行

```bash
python ./main.py
```

运行后，爬取的通知的title，time，link会被存储到相应的.xlsx文件中。并且每个通知的对应的内容(.txt)和词云图片(.png)会存储到该通知的文件夹中。

## 实现亮点

1.将通知的标题、时间和链接保存到Excel文件中，方便查阅和后续处理。

2.将每个通知的详细内容保存为文本文件，便于阅读和进一步分析。

3.生成每个通知词云图，进行可视化处理，更加直观。

## 注意事项
1.此脚本默认**utf-8**对中文字符进行编码，若爬取某些网页出现编码错误，可尝试改**gb**编码。若还是无法解决，可将出现编码错误的字符用replace函数将该字符用空字符替换（有可能影响阅读）。例如，
content=content.replace('\xa0','')

2.在测试爬虫代码时，请不要将请求频率设置得过高(~~有可能第二天你会发现自己上不去那个网站了~~)，请自觉遵守相关爬虫协议

## 联系方式和帮助

1.邮箱：siri-qin@qq.com

2.如果有任何问题或需要进一步的帮助,可以随时联系我